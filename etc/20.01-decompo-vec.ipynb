{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffce728e-1c00-4a5c-bea6-c6380990e6f2",
   "metadata": {},
   "source": [
    "# Decompose Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1f9ec6-425e-4aa4-bbc2-69417b93ee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c159d702-298e-45fd-88b1-bf606cea2084",
   "metadata": {},
   "source": [
    "## Data dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c90b3d5-0731-4db2-aab1-6a3439b4878a",
   "metadata": {},
   "source": [
    "```\n",
    "../data/tencent_d200_500k.bin 53f5b4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20a3390f-6c3f-4b31-b3a0-e77c4c1acadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/tencent_d200_500k.bin 53f5b4\n"
     ]
    }
   ],
   "source": [
    "from hashlib import sha1\n",
    "from pathlib import Path\n",
    "paths = [\"../data/tencent_d200_500k.bin\"]\n",
    "for path_x in paths:\n",
    "    h = sha1()\n",
    "    h.update(Path(path_x).read_bytes())\n",
    "    print(path_x, h.hexdigest()[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c293bc34-9608-4a9d-9923-0dd1b1cf22be",
   "metadata": {},
   "source": [
    "## Decomposition relations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec91b80-d344-4795-8490-919f5517049c",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "f(c_1, c_2) =& f(c_1, *) + f(*, c_2) - f(c_1, *) - f(*, c_2)\\\\\n",
    "             & + f(c_1, c_2) - f(c_1, c_2)\\\\\n",
    "             & + f(c_1, c_2) \\\\\n",
    "          =& \\left[f(c_1, c_2) - f(*, c_2)\\right]  \\\\\n",
    "           & + \\left[f(c_1, c_2) - f(c_1, *) \\right] \\\\\n",
    "           & + \\left[f(c_1, *) + f(*, c_2) - f(c_1, c_2)\\right] \\\\\n",
    "          = & \\delta(c_1|c_1, c_2) + \\delta(c_2|c_1,c_2) + \\delta(c_1, c_2)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93654955-3256-4094-8417-6f8b659d8b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kv = KeyedVectors.load_word2vec_format(\"../data/tencent_d200_500k.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61ebc6f9-8194-4d40-976e-9599d3908ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "biwords = []\n",
    "for x in kv.key_to_index.keys():\n",
    "    ## there are already some tokens including '*' in embedding\n",
    "    if len(x) != 2 or '*' in x: continue\n",
    "    biwords.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a57bee2-7c59-47f4-a1ab-0fbb7bc9009b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121562"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfd3ed1b-9eb0-4b96-b382-21e3d0831df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5340, 5266)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_c1 = {}\n",
    "vocab_c2 = {}\n",
    "for w in biwords:\n",
    "    c1, c2 = list(w)\n",
    "    vocab_c1.setdefault(c1, []).append(w)\n",
    "    vocab_c2.setdefault(c2, []).append(w)\n",
    "len(vocab_c1), len(vocab_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ac0d95a-9468-42f7-8d33-34d469e7ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_vec(wlist):\n",
    "    return np.vstack([kv.get_vector(x, norm=False) for x in wlist]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fef93651-f870-41ad-9b16-96046493b442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e44bef79cb42d4947c705d6a2964a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62f3c080f15461cb2c622c91c6b6ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "mu_list = []\n",
    "n_mu = len(vocab_c1) + len(vocab_c2)\n",
    "mu_vecs = np.zeros((n_mu, kv.vector_size))\n",
    "for c1x, wlistx in tqdm(vocab_c1.items()):    \n",
    "    # compute \\mu_c1 = mean(f(c1, *))\n",
    "    if len(wlistx) == 1: continue\n",
    "    vecx = compute_mean_vec(wlistx)\n",
    "    mu_vecs[len(mu_list), :] = vecx\n",
    "    mu_list.append(f\"{c1x}*\")\n",
    "\n",
    "for c2x, wlistx in tqdm(vocab_c2.items()):    \n",
    "    # compute \\mu_c2 = mean(f(*, c2))\n",
    "    if len(wlistx) == 1: continue\n",
    "    vecx = compute_mean_vec(wlistx)\n",
    "    mu_vecs[len(mu_list), :] = vecx\n",
    "    mu_list.append(f\"*{c2x}\")\n",
    "\n",
    "mu_vecs = mu_vecs[:len(mu_list),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "739c07f3-0554-4969-98b2-1da8a7008b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7950, (7950, 200))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mu_list), mu_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ade737ee-30b2-4798-9536-dacfb3971ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_kv = KeyedVectors(mu_vecs.shape[1])\n",
    "mu_kv.add_vectors(mu_list, mu_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3eb4d73-7469-4001-89d9-bb9dabc85ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2c3a0c6f1b4733afe69f3dbb694979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/121562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "delta_list = []\n",
    "n_delta = len(biwords) * 3\n",
    "delta_vecs = np.zeros((n_delta, kv.vector_size))\n",
    "for wx in tqdm(biwords):\n",
    "    c1x, c2x = list(wx)\n",
    "    wvecx = kv.get_vector(wx, norm=False)\n",
    "    \n",
    "    mu1x = f\"{c1x}*\"\n",
    "    mu2x = f\"*{c2x}\"\n",
    "    if mu1x in mu_kv:\n",
    "        mu_c1 = mu_kv.get_vector(f\"{c1x}*\", norm=False)\n",
    "        delta_c2 = wvecx - mu_c1\n",
    "        delta_vecs[len(delta_list), :] = delta_c2\n",
    "        delta_list.append(f\"d2({c2x}|{wx})\")    \n",
    "    else:\n",
    "        mu_c1 = wvecx\n",
    "        \n",
    "    if mu2x in mu_kv:\n",
    "        mu_c2 = mu_kv.get_vector(f\"*{c2x}\", norm=False)\n",
    "        delta_c1 = wvecx - mu_c2\n",
    "        delta_vecs[len(delta_list), :] = delta_c1\n",
    "        delta_list.append(f\"d1({c1x}|{wx})\")    \n",
    "    else:\n",
    "        mu_c2 = wvecx\n",
    "    \n",
    "    delta_c12 = mu_c1 + mu_c2 - wvecx\n",
    "    delta_vecs[len(delta_list), :] = delta_c12    \n",
    "    delta_list.append(f\"dw({wx})\")\n",
    "\n",
    "delta_vecs = delta_vecs[:len(delta_list), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5fec28d-64ae-4812-8da8-95d9c4d21aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362030, (362030, 200))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(delta_vecs), delta_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f08e761-24ad-41f8-925d-2aca64ff73c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace=True is important. We need to replace the existing '*' entries.\n",
    "kv.add_vectors(mu_list, mu_vecs, replace=True)\n",
    "kv.add_vectors(delta_list, delta_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95cbc8df-4ff8-4748-b5e3-86c09de1ae93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(delta_vecs.sum(1)==0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff55c992-1929-4e8a-ad72-69e1fd3d286c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(869958, 200)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dd7cdc1-52d8-4e9c-abd5-a230b6c157e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test equality\n",
    "import random\n",
    "random.seed(12345)\n",
    "sample_words = random.sample(biwords, 1000)\n",
    "\n",
    "for sample_x in sample_words:\n",
    "    tgt_word = sample_x\n",
    "    wv_x = kv.get_vector(tgt_word, norm=False)\n",
    "    tgt_c1, tgt_c2 = list(tgt_word)\n",
    "    delta_c1 = f\"d1({tgt_c1}|{tgt_word})\"\n",
    "    delta_c2 = f\"d2({tgt_c2}|{tgt_word})\"\n",
    "    delta_w = f\"dw({tgt_word})\"    \n",
    "    delta_c1v = 0; delta_c2v = 0\n",
    "    if delta_c1 in kv: delta_c1v = kv.get_vector(delta_c1, norm=False)\n",
    "    if delta_c2 in kv: delta_c2v = kv.get_vector(delta_c2, norm=False)\n",
    "    recon_v = delta_c1v + delta_c2v + kv.get_vector(delta_w, norm=False)\n",
    "    try:\n",
    "        assert np.allclose(recon_v, wv_x, atol=1e-5)\n",
    "    except:\n",
    "        print(sample_x, ((recon_v-wv_x)**2).sum())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13ee90f7-92f6-49bc-a79b-c1272c2832a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kv.allocate_vecattrs()\n",
    "kv.save_word2vec_format(\"../data/delta_tenc_d200_biwords.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5726773-6cdb-4f2a-a2e9-dbcbe59d1c96",
   "metadata": {},
   "source": [
    "## Output Hashes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc54e70-5386-425c-93e4-69a3b32a4db2",
   "metadata": {},
   "source": [
    "```\n",
    "../data/delta_tenc_d200_biwords.bin 04e3f4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7629e9c3-85b5-4ca0-948b-8b6b09bd0103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/delta_tenc_d200_biwords.bin 04e3f4\n"
     ]
    }
   ],
   "source": [
    "paths = [\"../data/delta_tenc_d200_biwords.bin\"]\n",
    "for path_x in paths:\n",
    "    h = sha1()\n",
    "    h.update(Path(path_x).read_bytes())\n",
    "    print(path_x, h.hexdigest()[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ca2873-ad9e-4836-8935-67f6a5aba38a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
